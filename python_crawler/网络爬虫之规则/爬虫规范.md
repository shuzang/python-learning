## 爬虫分类
- 爬取网页
 小规模，数据量小，爬取速度不敏感，Requests库
- 爬取网站，爬取系列网站
 中规模，数据规模较大，爬取速度敏感，Scrapy库
- 爬取全网
 大规模，搜索引擎，爬取速度关键，只能定制


## robots协议
>爬虫应当遵守robots协议，类人行为可不遵守，但不能用来牟利

robots.txt位于网站根目录下，其内容遵循如下规范：
```
# 注释，* 代表所有，/代表根目录
User-agent:*
Disallow:/
```